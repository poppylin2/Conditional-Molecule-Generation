{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1914692d",
   "metadata": {},
   "source": [
    "# ðŸ§¬ molGPT: Conditional Molecular Generation with Transformers\n",
    "\n",
    "**molGPT** is an end-to-end pipeline for generating novel drug-like molecules using a transformer-based language model (GPT-style). This project focuses on **conditional SMILES generation**, where molecular properties such as LogP, QED, TPSA, and scaffold are used to guide the generation process. It's an exciting intersection of **natural language processing** and **computational drug discovery**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Highlights\n",
    "\n",
    "- âœ… Trains a decoder-only transformer (GPT) to generate valid SMILES strings\n",
    "- ðŸŽ¯ Conditioned on molecular properties like:\n",
    "  - **LogP** (lipophilicity)\n",
    "  - **QED** (quantitative estimate of drug-likeness)\n",
    "  - **TPSA** (topological polar surface area)\n",
    "  - **Scaffold** (molecular backbone)\n",
    "- ðŸ“Š Includes evaluation metrics:\n",
    "  - SMILES validity\n",
    "  - Molecular uniqueness\n",
    "  - Structural novelty (Tanimoto similarity)\n",
    "  - Property alignment\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª Dataset\n",
    "\n",
    "Uses the [MOSES](https://github.com/molecularsets/moses) dataset â€” a curated collection of drug-like molecules, suitable for generative modeling.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c63098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dependencies\n",
    "\n",
    "# %pip install pandas rdkit transformers[torch] accelerate>=0.26.0\n",
    "# %pip install scikit-learn matplotlib tqdm pathos\n",
    "# %pip install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "# %pip install git+https://github.com/molecularsets/moses.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dffc94",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab94ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from functools import partial\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, QED, rdMolDescriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import GetScaffoldForMol\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2Config,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec9d07",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Filtering\n",
    "\n",
    " We'll use the MOSES dataset, which is a curated set of drug-like molecules specifically\n",
    " designed for machine learning applications. It's much smaller than ChEMBL\n",
    " (https://www.ebi.ac.uk/chembl/, database: https://chembl.gitbook.io/chembl-interface-documentation/)\n",
    " but still contains high-quality, drug-like compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03667ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-filtered dataset from dataset_v1_filtered.csv\n",
      "Loaded 1735494 pre-filtered drug-like molecules\n",
      "\n",
      "First few rows of filtered dataset:\n",
      "                                   SMILES  SPLIT\n",
      "0  CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1  train\n",
      "1    CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1  train\n",
      "2  CC1C2CCC(C2)C1CN(CCO)C(=O)c1ccc(Cl)cc1   test\n",
      "3     Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO  train\n",
      "4        Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C  train\n"
     ]
    }
   ],
   "source": [
    "def load_moses_data():\n",
    "    filtered_path = Path('dataset_v1_filtered.csv')\n",
    "    if filtered_path.exists():\n",
    "      print(f\"Loading pre-filtered dataset from {filtered_path}\")\n",
    "      df = pd.read_csv(filtered_path)\n",
    "      print(f\"Loaded {len(df)} pre-filtered drug-like molecules\")\n",
    "      return df\n",
    "    train_path = Path('dataset_v1.csv')\n",
    "    print(f\"Reading the original dataset from {train_path}\")\n",
    "    df = pd.read_csv(train_path)\n",
    "    print(df.info)\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    if 'smiles' in df.columns:\n",
    "      df = df.rename(columns={'smiles': 'SMILES'})\n",
    "    elif 'SMILES' not in df.columns:\n",
    "      print(\"Available columns:\", df.columns.tolist())\n",
    "      raise ValueError(\"No 'smiles' or 'SMILES' column found in the dataset.\")\n",
    "    smiles_list = df['SMILES'].values\n",
    "    print(f\"\\nFound {len(smiles_list)} SMILES strings in the dataset.\")\n",
    "\n",
    "    # Here we begin with filtering\n",
    "    valid_mols = []\n",
    "    for smi in tqdm(smiles_list, desc=\"Validating and filtering SMILES\"):\n",
    "      # Filter 1 ensures that all molecules are chemically and structurally valid\n",
    "      mol = Chem.MolFromSmiles(smi)\n",
    "      if mol is not None:\n",
    "        # Filter 2 makes sure molecules with physicochemical properties out of a desirable range are removed from the list\n",
    "        mw = Descriptors.ExactMolWt(mol) # Molecular weight (in Da units)\n",
    "        logp = Descriptors.MolLogP(mol) # LogP(measured lipophilicity, i.e., how much a molecule likes to be solved in fat versus water)\n",
    "        hbd = rdMolDescriptors.CalcNumHBD(mol) # Number of a molecule's hydrogen-bond donor heavy atoms\n",
    "        hba = rdMolDescriptors.CalcNumHBA(mol) # Number of a molecule's hydrogen-bond acceptor heavy atoms\n",
    "\n",
    "        if mw <= 500 and logp <=5 and hbd <= 5 and hba <= 10:\n",
    "          # Filter 3 screens for problematic chemical groups shown to be associated with toxicity, carcinogenicity, etc.\n",
    "          has_bad_groups = False\n",
    "          patt_list = [\n",
    "              '[N+]([O-])=O',  # Nitro groups: Highly reactive, can cause DNA damage and carcinogenicity\n",
    "              '[S](=[O])(=[O])',  # Sulfonyl groups: Can be chemically reactive and cause skin/eye irritation\n",
    "              '[P](=[O])',  # Phosphoryl groups: Potential toxicity and instability in biological systems\n",
    "              '[As]'  # Arsenic: Highly toxic heavy metal with severe health risks and carcinogenic properties\n",
    "          ]\n",
    "          for patt in patt_list:\n",
    "              if mol.HasSubstructMatch(Chem.MolFromSmarts(patt)):\n",
    "                has_bad_groups = True\n",
    "                break\n",
    "          if not has_bad_groups:\n",
    "            valid_mols.append(smi)\n",
    "\n",
    "    # Create the filtered dataframe\n",
    "    filtered_df = df[df['SMILES'].isin(valid_mols)]\n",
    "    print(f\"\\nAfter filtering, {len(filtered_df)} molecules remain\")\n",
    "    return filtered_df\n",
    "\n",
    "# Load and display filtered data\n",
    "filtered_df = load_moses_data()\n",
    "print(\"\\nFirst few rows of filtered dataset:\")\n",
    "print(filtered_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd5ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(\"dataset_v1_filtered\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61538fc",
   "metadata": {},
   "source": [
    "## 3. Descriptor Calculation (Scaffolds, logP, QED, TPSA)\n",
    " We compute additional descriptors needed:\n",
    " - Murcko Scaffolds: Core molecular framework obtained by removing side chains and keeping only ring systems and linkers between rings\n",
    " - QED\n",
    " - TPSA\n",
    " - LogP\n",
    "\n",
    "We'll store these in the DataFrame alongside the SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e19a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating molecular descriptors...\n",
      "Detected 16 CPU cores\n",
      "Running descriptor calculations in parallel across 16 cores\n",
      "Processing 1735494 SMILES strings in 17355 batches\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab781cbd7ff444abe2d7249caa9a164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/17355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'calculate_descriptors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"d:\\Program Files (x86)\\Python\\Lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"d:\\Program Files (x86)\\Python\\Lib\\site-packages\\pathos\\helpers\\mp_helper.py\", line 15, in <lambda>\n    func = lambda args: f(*args)\n                        ^^^^^^^^\n  File \"C:\\Users\\Y\\AppData\\Local\\Temp\\ipykernel_31344\\3514142907.py\", line 23, in process_batch\nNameError: name 'calculate_descriptors' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 73\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTPSA range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPSA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPSA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 73\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_descriptors_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[5], line 42\u001b[0m, in \u001b[0;36mcalculate_descriptors_parallel\u001b[1;34m(df, parallel, batch_size)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(smiles_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m SMILES strings in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool() \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m---> 42\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing batches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Program Files (x86)\\Python\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program Files (x86)\\Python\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\Program Files (x86)\\Python\\Lib\\site-packages\\multiprocess\\pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31mNameError\u001b[0m: name 'calculate_descriptors' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_descriptors(smiles: str):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if not mol:\n",
    "        return None, None, None, None\n",
    "\n",
    "    try:\n",
    "        scaffold = GetScaffoldForMol(mol)\n",
    "        scaffold_smiles = Chem.MolToSmiles(scaffold)\n",
    "\n",
    "        qed_val = QED.qed(mol)\n",
    "\n",
    "        tpsa_val = rdMolDescriptors.CalcTPSA(mol)\n",
    "\n",
    "        logp_val = Descriptors.MolLogP(mol)\n",
    "\n",
    "        return scaffold_smiles, logp_val, qed_val, tpsa_val\n",
    "    except:\n",
    "        return None, None, None, None\n",
    "\n",
    "def process_batch(smiles_batch):\n",
    "    results = []\n",
    "    for smi in smiles_batch:\n",
    "        results.append(calculate_descriptors(smi))\n",
    "    return results\n",
    "\n",
    "def calculate_descriptors_parallel(df, parallel=True, batch_size=100):\n",
    "    print(\"Calculating molecular descriptors...\")\n",
    "\n",
    "    if parallel:\n",
    "        n_cores = Pool().ncpus\n",
    "        print(f\"Detected {n_cores} CPU cores\")\n",
    "        print(f\"Running descriptor calculations in parallel across {n_cores} cores\")\n",
    "\n",
    "        smiles_list = df['SMILES'].tolist()\n",
    "        n_batches = (len(smiles_list) + batch_size - 1) // batch_size\n",
    "        batches = [smiles_list[i*batch_size:(i+1)*batch_size]\n",
    "                  for i in range(n_batches)]\n",
    "\n",
    "        print(f\"Processing {len(smiles_list)} SMILES strings in {n_batches} batches\")\n",
    "\n",
    "        with Pool() as pool:\n",
    "            results = list(tqdm(\n",
    "                pool.imap(process_batch, batches),\n",
    "                total=n_batches,\n",
    "                desc=\"Processing batches\"\n",
    "            ))\n",
    "\n",
    "        all_results = [item for batch in results for item in batch]\n",
    "\n",
    "    else:\n",
    "        print(\"Running descriptor calculations sequentially\")\n",
    "        all_results = []\n",
    "        for smi in tqdm(df['SMILES'], desc=\"Calculating descriptors\"):\n",
    "            all_results.append(calculate_descriptors(smi))\n",
    "\n",
    "    scaffolds, logps, qeds, tpsas = zip(*all_results)\n",
    "\n",
    "    df['Scaffold'] = scaffolds\n",
    "    df['LogP'] = logps\n",
    "    df['QED'] = qeds\n",
    "    df['TPSA'] = tpsas\n",
    "\n",
    "    df = df.dropna(subset=['Scaffold', 'LogP', 'QED', 'TPSA'])\n",
    "    print(f\"Final dataset size after descriptor calculation: {len(df)}\")\n",
    "\n",
    "    print(\"\\nDescriptor Statistics:\")\n",
    "    print(f\"LogP range: {df['LogP'].min():.2f} to {df['LogP'].max():.2f}\")\n",
    "    print(f\"QED range: {df['QED'].min():.2f} to {df['QED'].max():.2f}\")\n",
    "    print(f\"TPSA range: {df['TPSA'].min():.2f} to {df['TPSA'].max():.2f}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "filtered_df = calculate_descriptors_parallel(filtered_df, parallel=True)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474988c2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
